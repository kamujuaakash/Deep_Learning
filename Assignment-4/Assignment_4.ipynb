{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3b63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4ff54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataCreation(data_size,start,end):\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    input_size = torch.randint(start,end,(data_size,))\n",
    "    for i in range(data_size):\n",
    "        first_layer = torch.rand(input_size[i])\n",
    "        x_0 = torch.randint(0,input_size[i],(1,))\n",
    "        x_1 = torch.randint(1,input_size[i],(1,))\n",
    "        if (x_1 == x_0):\n",
    "            x_1 = x_1 - 1\n",
    "        second_layer = torch.zeros(input_size[i])\n",
    "        second_layer[x_0] = 1\n",
    "        second_layer[x_1] = 1       \n",
    "        input_data.append(torch.stack((first_layer,second_layer)))\n",
    "        output_data.append(first_layer[x_0] + first_layer[x_1])\n",
    "    return(input_data,output_data,data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fa64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data,output_data,data_size = DataCreation(5000,2,10)\n",
    "test_input,test_output,test_data_size = DataCreation(1000,2,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5d810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, optimizer,data_size,input_data,output_data):\n",
    "    loss_m = 0\n",
    "    for i in range(data_size):\n",
    "# Compute prediction\n",
    "        X = input_data[i]\n",
    "        y = output_data[i]\n",
    "        pred = model(X)\n",
    "# Calculating loss\n",
    "        loss = loss_fn(pred, y)\n",
    "# Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_m = loss_m + loss.detach()\n",
    "    return loss_m/data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "432a8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    h = 5\n",
    "    C = 5\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.h0 = (torch.zeros(self.h,1))\n",
    "        self.C0 = (torch.zeros(self.C,1))\n",
    "        \n",
    "#         variables\n",
    "        self.Wf = nn.Parameter(torch.randn(self.h,self.h+2)/np.sqrt(self.h + 2))\n",
    "        self.bf = nn.Parameter(torch.randn(self.h,1))\n",
    "        self.Wi = nn.Parameter(torch.randn(self.h,self.h + 2)/np.sqrt(self.h + 2))\n",
    "        self.bi = nn.Parameter(torch.randn(self.h,1))\n",
    "        self.Wc = nn.Parameter(torch.randn(self.h,self.h + 2)/np.sqrt(self.h + 2))\n",
    "        self.bc = nn.Parameter(torch.randn(self.h,1))\n",
    "        self.Wo = nn.Parameter(torch.randn(self.h,self.h + 2)/np.sqrt(self.h + 2))\n",
    "        self.bo = nn.Parameter(torch.randn(self.h,1))\n",
    "        self.Wy = nn.Parameter(torch.randn(1,self.h))\n",
    "        self.by = nn.Parameter(torch.randn(1,1))\n",
    "    def forward(self,xt):\n",
    "        self.ht = self.h0\n",
    "        self.Ct = self.C0        \n",
    "        Tanh = nn.Tanh() # Tanh non-linearity\n",
    "        Sigmoid = nn.Sigmoid() # Sigmoid non-linearity\n",
    "        for i in range(len(xt)):\n",
    "            cathx = torch.cat((self.ht,xt[:,i].unsqueeze(1)))\n",
    "            self.ft = Sigmoid(self.Wf@(cathx) + self.bf)\n",
    "            self.it = Sigmoid(self.Wi@(cathx) + self.bi)\n",
    "            self.C_t = Tanh(self.Wc@(cathx) + self.bc)\n",
    "            self.Ct = self.ft*self.Ct + self.it*self.C_t\n",
    "            self.ot = Sigmoid(self.Wo@(cathx) + self.bo)\n",
    "            self.ht = self.ot*Tanh(self.Ct)\n",
    "        y = self.Wy@self.ht + self.by\n",
    "        return y[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66a7530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:0.13900193572044373\n",
      "Epoch 2:0.11710097640752792\n",
      "Epoch 3:0.10268054157495499\n",
      "Epoch 4:0.09985484927892685\n",
      "Epoch 5:0.09862888604402542\n",
      "Epoch 6:0.09793183952569962\n",
      "Epoch 7:0.0975293442606926\n",
      "Epoch 8:0.09728448837995529\n",
      "Epoch 9:0.09712030738592148\n",
      "Epoch 10:0.09699955582618713\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model_2 = LSTM()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.02)\n",
    "LSTM_loss = torch.empty([1])\n",
    "current_loss = 100\n",
    "epochs = 0\n",
    "while True:\n",
    "    if (\n",
    "#         abs(current_loss) > 0.05 and \n",
    "        epochs < 10) :\n",
    "            current_loss = train_loop(model_2, loss_fn, optimizer,data_size,input_data,output_data)\n",
    "            print(\"Epoch {}:{}\".format(epochs+1,current_loss))\n",
    "            LSTM_loss = torch.cat((LSTM_loss,torch.tensor([current_loss])))\n",
    "            epochs = epochs + 1\n",
    "    else:\n",
    "        break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        ht = self.h0\n",
    "        Ct = self.C0\n",
    "        for i in range(len(xt)):\n",
    "            cathx = torch.cat((ht,xt[:,i].unsqueeze(1)))\n",
    "            ft = torch.sigmoid(self.Wf@(cathx) + self.bf)\n",
    "            it = torch.sigmoid(self.Wi@(cathx) + self.bi)\n",
    "            C_t = torch.tanh(self.Wc@(cathx) + self.bc)\n",
    "            Ct = (ft*Ct) + (it*C_t)\n",
    "            ot = torch.sigmoid(self.Wo@(cathx) + self.bo)\n",
    "            ht = (ot*torch.tanh(Ct))\n",
    "        y = self.Wy@ht + self.by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d26a7f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ht \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mh0\n\u001b[0;32m      2\u001b[0m Ct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC0\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(xt)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "        self.ht = self.h0\n",
    "        self.Ct = self.C0        \n",
    "        Tanh = nn.Tanh() # Tanh non-linearity\n",
    "        Sigmoid = nn.Sigmoid() # Sigmoid non-linearity\n",
    "        for i in range(len(xt)):\n",
    "            cathx = torch.cat((self.ht,xt[:,i].unsqueeze(1)))\n",
    "            self.ft = Sigmoid(self.Wf@(cathx) + self.bf)\n",
    "            self.it = Sigmoid(self.Wi@(cathx) + self.bi)\n",
    "            self.C_t = Tanh(self.Wc@(cathx) + self.bc)\n",
    "            self.Ct = self.ft*self.Ct + self.it*self.C_t\n",
    "            self.ot = Sigmoid(self.Wo@(cathx) + self.bo)\n",
    "            self.ht = self.ot*Tanh(self.Ct)\n",
    "        y = self.Wy@self.ht + self.by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3842cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "           concat_vec = torch.cat((self.h_t,input_))\n",
    "           self.f_t = Sigmoid(self.Wf@concat_vec + self.bias_f) # To do selective erase of prev hidden state\n",
    "           self.i_t = Sigmoid(self.Wi@concat_vec + self.bias_i) # To do selective read from prev hidden state\n",
    "            \n",
    "           cand = Tanh(self.Wc@concat_vec + self.bias_c) # Candidate cell state\n",
    "           \n",
    "           self.C_t = self.C_t*self.f_t + self.i_t*cand # New cell state\n",
    "           self.o_t = Sigmoid(self.Wo@concat_vec + self.bias_o) # To do selective write on prev hidden write\n",
    "           self.h_t = Tanh(self.C_t)*self.o_t # New hidden state\n",
    "        \n",
    "        self.y_smp = self.Wy@self.h_t + self.bias_y # Output predicted by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9db5756b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1384167505.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.C_t = self.C_0\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " self.h_t = self.h_0\n",
    "        self.C_t = self.C_0\n",
    "        \n",
    "        Tanh = nn.Tanh() # Tanh non-linearity\n",
    "        Sigmoid = nn.Sigmoid() # Sigmoid non-linearity\n",
    "\n",
    "        for input_ in input_sq:\n",
    "            \n",
    "           input_ = input_.view(-1,1) # Adjusting the input to appropriate shape\n",
    "        \n",
    "           concat_vec = torch.cat((self.h_t,input_)) # Concatenating the hidden state and input  \n",
    "           \n",
    "           self.f_t = Sigmoid(self.Wf@concat_vec + self.bias_f) # To do selective erase of prev hidden state\n",
    "           self.i_t = Sigmoid(self.Wi@concat_vec + self.bias_i) # To do selective read from prev hidden state\n",
    "            \n",
    "           cand = Tanh(self.Wc@concat_vec + self.bias_c) # Candidate cell state\n",
    "           \n",
    "           self.C_t = self.C_t*self.f_t + self.i_t*cand # New cell state\n",
    "           self.o_t = Sigmoid(self.Wo@concat_vec + self.bias_o) # To do selective write on prev hidden write\n",
    "           self.h_t = Tanh(self.C_t)*self.o_t # New hidden state\n",
    "        \n",
    "        self.y_smp = self.Wy@self.h_t + self.bias_y # Output predicted by model\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
